+++
title = "You don't have to if you don't want to."
description = 'TODO The description goes here.'
#subheading = 'The subheading goes here.'
date = 2026-02-16

#[[infoBox]]
#key = 'AI Disclosure :sparkles:'
#value = 'Ideally this is not needed.'
+++

I'm sure you're wondering why I called you all here today. Well, to be honest, I didn't actually call for _all_ of you; some of you probably shouldn't be here. You folks might want to quietly find your way to the exits right here and right now.

For those readers who are sticking around, I suspect I'm going to lose a fair number of you along the way. We're going to attempt to thread a pretty tough needle here and I won't be too terribly offended if some browser tabs get closed before we get there.

And hell, may as well say it: The opinions expressed here belong solely to me and do not reflect the views of my employer, and they probably don't reflect the views of anyone else's employer either.

This is for the people who look at the world and feel like everything and everybody has gone crazy. People who maybe have this nagging feeling deep inside that something isn't right here, but may be unsure about speaking up for fear of being ostracized at work or in social circles. Those of us who pause, look at this barrage of everything happening around us every day, and simply want to say no.

If anyone out there has felt for the very first time that this might finally be the "new trick" that makes them feel like an "old dog," or if you're a fresh graduate who spent years working through school toward an almost-certain career path that seems now to be crumbling into dust underfoot, you are the intended audience.

I'm writing this to tell you that it's not just you. But more importantly, you're not wrong. You are free to feel what you feel and think what you think. And I, for one, am tired of listening to people that tell me to suppress those parts of myself and surrender to a new way of being that I never asked for and frankly do not want.

Pull up a chair and endure yet another goddamn article about generative AI.

## Gotta blame it on something

In 1989, a musical act called Milli Vanilli had a number one hit titled "Baby Don't Forget My Number." This, along with the earlier single "Girl You Know It's True" secured them a spot on the _Club MTV Tour_. During one of the performances, a technical glitch caused their pre-recorded vocal track to skip and repeat, clearly betraying the fact that they had been lip-syncing to the voices of other singers. It didn't take long before news broke that the performers on the stage that night had never sung _any_ of their music---live or album versions.

In the fallout from this incident, their record label severed ties with them, their Grammy award was rescinded, and their albums were pulled from shelves. The performers{{% margin-note side %}}Fab Morvan and Rob Pilatus{{% /margin-note %}} never found any lasting success after the dissolution of the group. Lawsuits were filed by groups of customers who felt like they were sold fraudulent goods using deceptive practices. To this day, the name Milli Vanilli remains tainted by the scandal.

Maybe it's just me, but I feel that same kind of treachery when somebody tries to pass off a piece of AI-generated work as if it were their own. There's always that moment---whether reading the text, examining the image, or listening to the spoken language---where I clock the presentation as "not quite right." Then the realization hits that I've been engaging with nothing of any particular substance, then I become a little pissed off at having my time and attention wasted by somebody who didn't care enough about what they were doing to actually do that thing.

Recently that feeling of indignation has started becoming displaced by something a bit more melancholy. AI restaurant reviews praising a dish that definitely is not offered on the menu, and the attentive service provided by a named member of the staff who doesn't exist. Video recommendations featuring an algorithmic guess at the swimming motions of a newborn sea otter or the smile of a down-on-his luck war vet reuniting with a service dog. Has anybody with a mouth ever tasted this cookie recipe? Has anybody with an actual butt contributed any of the five-star reviews listed next to this computer chair?

We've got enough content to infinite-scroll for the rest of our waking lives. Yet so much of it is pointless, unnecessary, lacking substance, or actively harmful. It is above all _joyless_---like listening to a Breaking Rust album {{% margin-note %}}There has been plenty of commentary regarding the 100% AI-produced track "Walk My Walk," but there is some real gold in the Singles and EPs category of Breaking Rust's artist page on Spotify. In particular, a relatively recent cover of "Photograph" that answers the question "What if we got Ben E. King's backing band, put a Temu clone of Chris Stapleton's voice on top of it, and did an Ed Sheeran song that went for _eight and a half minutes?_" It is not pleasant and it does not need to exist.<br><br>If that's not to your taste, there's also an eleven minute version of Passenger's "Let Her Go" up there. (Everything okay with your EOS tokens, buddy? Just concerned is all.){{% /margin-note %}} and eating a sleeve of unsalted saltines---while somehow forgetting that it wasn't always this way.

Look at LinkedIn for chrissakes. "A senior engineer was tasked with such-and-such," "The consultant billed for 60 hours," "Our backlog had grown to over a thousand tickets," "When I saw the 350,000 line pull request the junior engineer had opened," and on and on. These are not real things that have happened to living people. They are the result of somebody prompting a chat bot to "make me sound smart and insightful to a room full of people who have long since turned their brains off" while conveying nothing novel or actionable. I have recently started referring to these "thought" "leadership" social media posts collectively as **AIslop's Fables**.

If you'll indulge me, I'd like to take a brief tangent and try my hand at writing one of these ridiculous things myself:

> Two engineers---the systems architect Ass and the solution consultant Weasel---chanced to travel in company down a forest aisle. The Ass walked purposefully several paces ahead of the Weasel, who dawdled merrily along. At last they paused at a fork in the codebase.
>
> The Ass, ever considerate of the broader consequences of his actions, contemplated deeply the choice before him. The Weasel, uninterested in such unrewarding efforts, took rest at the base of a widespreading trie, finding great pleasure in the cool shade of its stable branches.
>
> So offended was the Ass at this display of poor work ethic, he deigned to question the Weasel's technical ability. "How foolish you should be," he brayed, "to remain unbothered by the fact that your house contains one appliance called a washing machine and another called a dishwasher. Until you see the absurdity of it, you have no business designing an API!"
>
> It was in that moment, and all at once, when Jupiter cast down a fierce reallocation of resources that made both of their roles redundant.
> <footer>The AIslopica 001. The Ass and the Weasel</footer>

Anyway. I find that when I mentally filter out all the obvious AI flourishes---the empty fluff, the excessive emoji, the formatting smells, the Ghibli-inspired scenes that really, _really_ love using every available shade of brown---there's sometimes not a whole lot of genuine human connection left in there. And in that empty space, I begin to wonder: Where did all the people go? What are they all doing behind the artifice they're showing here? Why am I wasting my time and energy wading through these shallow but unbounded seas of _nothing?_

For a while I was able to navigate around it by really curtailing my use of social media. I only looked at LinkedIn for the S-tier trolling of a select group of professional shitposters. Reddit no longer occupied any appreciable amount of my time. There are now entire classes of Hacker News submissions that I refuse to read the comments on. {{% margin-note %}}Including the comments about this article, should such comments ever materialize.{{% /margin-note %}} I experimented with a small set of browser customizations to eliminate YouTube video recommendations and the site's ill-conceived "Shorts."

In place of all that, I started spending much more time in smaller private communities of people with shared interests, personalities, or life experience. We'd swap links to things we think might be interesting to the group. We wouldn't chase trends, we didn't let ourselves get overloaded with shiny distractions from outside the circle, and we evolved it into a shared space that suited all of us best. Spending time in these small isolated groups really laid bare how _dogshit_ the social landscape on the broader internet felt in comparison.

I was all set to leave that part of my life behind me. Then it followed me to work.

## If a clod be washed away by the sea

There are lots of different jobs out there, and a fair number of them are done on computers. As a matter of fact, when people ask me what I do for a living, I sometimes simply wave my hand and say "Computers" in a kind of no-you-really-don't-want-to-know-what-Kubernetes-is kind of way. I suspect most office workers have a similar aspect of their job that they don't like to dredge up during polite conversation.

I'm a software engineer on paper, and that's the framing I'll use here because it's the one I know best. But I'm sure that those working in design, marketing, visual art, customer service, writing, all sorts of disciplines have felt it too. This ever-louder voice booming from on high to integrate LLMs and other generative AI tools into every conceivable point in your workstream. Maybe against your will. Probably against your own interests.

In the software engineering world, at least until quite recently, we all wrote computer code. Some of us wore the title "Coder" like a badge of honor to describe the profession.{{% margin-note side %}}I never much cared for it.{{% /margin-note %}} We spent basically the entire 2010s loudly promoting "Everyone should learn to code!" as the cure for all of the ails of that era. And coders entered the profession in droves. With a _teeny-tiny_ bit of help from years and years of interests rates near zero, the industry flourished.

There are a bunch of different types of computer code, and one way to visualize the different categories is to imagine them as the different decks on a ship. At the bottom, in the ship's sweltering boiler room, we have the **machine code**---the ones and zeros computers are real good at but humans are real bad at. Above that we have an **assembly language** layer, still cryptic as all hell but at least comprehensible to a skilled and attentive person who subsists entirely on coffee. Above that we have **systems languages** like C and Rust {{% margin-note %}}And maybe Go if you wanna get into fights with certain people.{{% /margin-note %}} that are a pretty good balance between raw control over the computer and ease of getting things done.

One deck higher, we find ourselves among the **interpreted languages** like Python and JavaScipt which hide a whole bunch of underlying concepts away in the name of making the code easier to write and reason about. And yet above that, a whole ecosystem of **low-code** tools that boast a point-and-click interface to building the whole application on top of their hosted platform. These would be things like Framer and Squarespace.

In this hierarchy, the upper level languages mechanically generate the code at the layer(s) beneath. If you are working in assembly code, a tool called an **assembler** translates it into machine code without you needing to think about it. If you write C or Rust, a **compiler** takes care of the assembly aspects of the program. Python and JavaScript are executed by **interpreters**, which were each written in a compiled language, and so on. Whichever layer you work in, your code ultimately needs to be translated all the way down to machine code for a computer to make any direct use of it.

What we've got now is perhaps the uppermost deck of that ship: **prompt driven development**. No direct manipulation of code of any sort, not even any pointing and clicking to move different pieces of the app around to suit your tastes. No, in this paradigm you type out exactly what you want in plain English, and an LLM chews on that prompt for a little while and then writes the necessary code in one of the lower-level languages on your behalf. Don't like what comes out? Prompt it again, and the code will change to something else. Precisely how does it change? It is none of your concern. Same as how when you change a line of Python code, most people really don't get to see what that does at the assembly level either.

There is a key difference here: When you change that line of Python code, you _can_ know what that affects. Every step in the process of executing that code adheres to a rigid set of rules that is followed precisely, each and every time. You can know that extending a string past a certain length triggers a memory allocation, and in this one degenerate case it causes a register spill leading to a performance hitch that can be reliably replicated, tested for, and worked around. It's deeply tedious to trudge through each deck of the ship this way, but it is feasible.

How does an LLM produce its output? Nobody knows. I mean, we _know_ in the abstract sense, but not in a way where we can attribute a certain behavior to a given machine state. It's simply not possible to trace what occurred across the hundreds of billions of parameters that underpin each model and replay even a fraction of the steps that transformed a given piece of context into a specific output token. We tend to call this **nondeterminism**, where the output of a system varies based on factors beyond of what was provided as input.{{% margin-note side %}}Compare this with the quote "Insanity is repeating the same mistakes and expecting different results" (which apparently originated in a Narcotics Anonymous pamphlet).{{% /margin-note %}} Turns out this property has a tendency to break existing code during attempts to make unrelated changes. To solve that, the industry has turned to **coding agents** that incrementally make these changes in a loop, ideally finding a stable equilibrium where the new thing works and none of the existing things broke. This is pretty much where we are now, with some engineers experimenting with running multiple agents concurrently to observe and correct each other's work.

But you didn't come here for a slapdash and oversimplified explanation of 80 years of programming history. You're here for boat metaphors!

Long time ago, probably before either you or I got into this game, the old RMS _Software Engineering_ struck an iceberg that tore a big gaping hole down the side of her hull. The Machine Code deck flooded first, and like literal rats escaping a literal sinking ship, the machine programmers sought higher ground on the Assembly Language deck. Water began flooding the assembly programmers out, and aside from a few air pockets where the embedded systems programmers sought refuge, everyone hurried up to C deck.

By this point, news had spread that "up near the top" was where everybody wanted to be---although the reasons _why_ got a little lost in the hustle---so a huge number of programmers arrived at the Interpreted Language decks. {{% margin-note %}}This was pretty much where I came in.{{% /margin-note %}} Some hung around for a good fifteen or twenty years, but the rising water waits for nobody. Higher still we climbed, skipping right past the Low-Code mezzanine and straight up to the Prompting promenade on the main deck. It is here that we've reached the top of our game; there's nothing above us but the twinkling stars punctuating the pitch black sky. From here, all the decks below do our bidding. With just a flick of the wrist, huge quantities of lower-level code are willed into existence without intervention. Simply marvelous.

Except... the ship is still taking on water. Sooner or later every deck---including the one the prompters are now standing on---will eventually go under. If you subscribe to the idea that technology will invariably improve and build on top of everything that has come before it, often to the point of completely encapsulating it, why is "writing all that prompt text" such a magical bright red line of job security? Text was the _first thing_ language models ever produced! You really can't envision a future where people think it's quaint and old-timey to write LLM prompts by hand?

And what happens to us in that metaphor? Just chillin', clinging to flotsam, slowly freezing to death in the North Atlantic.

## yolo;dr

Let me be crystal clear: Not everybody wants to write software in paragraph form.

In fact, I might propose the possibility that the techniques emerging today are a totally distinct discipline from traditional software engineering. Perhaps the two might coexist if we could simply agree to stay the hell out of each other's lanes.

But let's be real, that's not how this seems to be going.

At multiple points in my life, I've had the opportunity to debate my peers over the following question: Is software engineering an art, or a science? The science argument is bolstered by the fact that a disheartening proportion of people who work in the industry seem utterly incapable of appreciating art in any capacity, let alone creating any. On the other side, they've had the affirmation "code is poetry" emblazoned on the footer of the WordPress.org site {{% margin-note %}}And to date, the only form of poetry for which MITRE has assigned multiple CVEs.{{% /margin-note %}} for nearly a quarter century. I've long believed---and still believe---that software must be both. Look at a cable-stayed bridge, or a Tim Hunkin sculpture, or some of the stupid shit the contestants on _The Great British Baking Show_ have been asked to make over the past couple of seasons, and tell me that these didn't require the unique touch of an artist _and_ an engineer. In the right light, software is no different from these things.

Engineers work in specifications and requirements. The end product needs to behave a certain way, adhere to certain external constraints, meet relevant regulatory criteria, not kill anybody,{{% margin-note side %}}Unless the requirements say it should.{{% /margin-note %}} that type of thing. Artists work in the ambiguous undefined spaces that permeate all the little in-between areas of the work. Somebody has to make the countless tiny decisions that aren't otherwise spelled out in black and white on the ticket. The sum total of all these little decisions becomes something that looks and feels a lot like style, even taste. The choices being made here are influenced by a working lifetime of personal experiences. Perhaps one could go as far as suggesting that it involves a certain intuition to do it well. We're really okay with outsourcing this aspect of our work to some tensor core randomly burping out floating point rounding errors?

There are countless ways to express the same idea. Are some expressions of a particular idea better than others? Arguably!

"But wait," I hear you cry. "Once the product ships, nobody sees the code anyway! Who cares how it looks?" Take a long, hard look around you. Look at your phone. Look at one of the dozens of other web pages you have open. Look at the app launcher on your smart TV. Look at the {{% internal-link et-tu-panera %}}ordering kiosks at Panera{{% /internal-link %}}. Look at every furtive data broker who breached your personal information and offered a $200 credit monitoring voucher{{% margin-note side %}}You never bothered to redeem that, did you?{{% /margin-note %}} as restitution for their negligence. Look at every hateful airline website or clunky automotive touchscreen or inkjet printer driver and tell me with a straight face that code quality doesn't matter---that whatever makes these products so _miserable_ to interact with day in and day out could not _in any way_ be improved by exercising more care in the expression of the underlying code.

Look around you. You don't believe that this could be true?

When I hear people say "I ship code that I don't read," what I hear in my head is "I really do not care about what the end-user of this product experiences, I do not care about whichever poor soul needs to maintain this thing after I've gotten bored with paying attention to it, I do not care about anybody on my team who has to support the ongoing operation of it, and frankly I didn't even care about making it in the first place. I just wanted to be done for the sake of being done." It is a vulgar display of apathy, a willful dereliction of sound engineering practices, and quite frankly it makes the practitioner sound like an insufferable asshat. To wield something so limitlessly powerful as software without so much as the slightest reverence for the craft is simply offensive. Truly. I am viscerally disgusted by what I am watching transpire in this space.

"Aha! I've got you now," you bellow, in a different style of voice for some reason. "This is gatekeeping! You are trying to protect your little clubhouse from outsiders with viewpoints that differ from yours!" Guilty as charged; I am indeed gatekeeping. I'm gatekeeping in the same way all those pesky government officials gatekeep when they tell us we're not allowed to work toward achieving nuclear fission in the shed. Turns out we all live in a society, and the actions of one person have the capacity to directly and indirectly affect countless others. If there's an activity that has a high likelihood of causing preventable injury or tying up first responders unnecessarily, those activities tend to get restricted in some way.

Software runs the world. It can make (or lose) untold sums of money. It can decide who gets a favorable mortgage rate or a critical job interview. It can surveil us. It can bombard us with advertisements targeted at personality traits we're not even aware we're revealing. It can cause accidental (or deliberate) death. More commonly, it can really frustrate, annoy, inconvenience, and subtly chip away at the mental well-being of vast swaths of the inhabitants of this planet we all share. Stop treating it like it's anything less.

## I owe my soul to the company store

Not everybody is okay with the idea of becoming dependent on an outside party to do their work.

_Tools._ That's the word that everybody likes to volley around. These things are tools, the same kind of thing as what I get from Home Depot when I rent a wallpaper steamer. Same as what companies get when they pay Adobe for a Photoshop subscription. Gotta spend money to make money, as the saying goes. "LLM coding agents are tools---nothing more---so just pay for a license seat and use it like you would any other tool."

You ever get the feeling that something is different about the AI case, but you can't quite put your finger on it? You ever say a word like 'couch' out loud too many times, and the sound momentarily loses its meaning? {{% margin-note %}}There's a term for the phenomenon, by the way: semantic satiation.{{% /margin-note %}} Did we all collectively forget precisely what a tool even is?

Suppose there's a slotted-head screw somewhere in your environment that you wish to tighten. You could extend the index finger on your dominant hand, insert the free edge of your nail plate into the slot, and turn your wrist. Depending on the state of the screw, this will probably cause some amount of injury to your fingernail. The mental imagery of that certainly made me cringe a little.

A far more effective technique would be to find a slotted screwdriver, grasp it in your hand, and perform substantially the same motion to accomplish the task. Brains have the rather remarkable ability to treat handheld objects as an extension of the body without a whole lot of cognitive overhead. Both a fingernail and a screwdriver permit a being of free will to impart some change in their environment. These are pretty unambiguously tools.

The elegant simplicity of the screwdriver makes it useful for more than just driving screws. One could---in a pinch---use a screwdriver to pry two pieces apart, or to shave a piece of wood or other malleable material down, or they could bring it down to the mess hall to finally shank Jimmy the Rat. Whatever a person might want to do with a hand-held object having a screwdriver's material properties, they are free to do it.

Somewhere in another part of town, on the fourth floor of a three-star chain hotel, an ice machine hums dutifully in the elevator lobby. This is a self-contained appliance that draws utility power and water from the building and converts it into ice cubes.{{% margin-note side %}}Along with noise and waste heat.{{% /margin-note %}} That's all it does, all day every day, whether anyone is paying attention to it or not. Is the ice machine a tool? Is it being directly manipulated by a being of sapience to achieve a particular end result? Or is it simply a machine, just "there" in case somebody needs the convenience?

Conceptually between these two objects, we have the power screwdriver. This is a handheld device that converts electrical power into torque{{% margin-note side %}}Along with noise and waste heat.{{% /margin-note %}} that turns a slotted bit. The operator manipulates this in a way that's not too different from the regular screwdriver, moving it around and positioning the bit in the screw head, but instead of doing the difficult work of twisting their wrist to move the screw, all they need to do is press a button to release stored energy and channel it into the act of turning it. {{% margin-note %}}They also need to know when to _release_ the button, a lesson that comes from years of stripped threads, cammed-out heads, and splintered wood.{{% /margin-note %}} This is a far more efficient way to drive screws. It allows more screws to be driven over a given span of time, and it conserves the operator's energy and really saves their wrist from long-term injury.

Yet in removing the most laborious and time-consuming part of turning screws, the power screwdriver has lost some of the generality that the traditional screwdriver enjoyed. Its awkward form factor and stubby bit/chuck arrangement prevents it from being useful at prying or chiseling, and it's definitely not an effective way to deal with our pesky cellmate.

In fact, the narrow specialization of the power screwdriver is part of the reason why traditional screwdrivers still exist. I would guess that almost every person with a power screwdriver in their garage also has _multiple_ regular screwdrivers too. They each have their time and their place. I would not use a power screwdriver to change a watch battery, and I would not use a regular screwdriver to mount a 65-inch TV to a pair of wall studs. Both of these things are in my toolbox; I see no difficulty calling both of them tools.

So, what is generative AI? Is it a power screwdriver that removes sporadic moments of fleeting agony from a much larger home improvement project? Is it an ice machine loudly grinding unrequested ice cubes onto the tile floor at two o'clock in the morning? Or is it a stick of dynamite---light the fuse, plug your ears, and run the hell away from whatever happens next?

It can be all of these things, it seems. I guess AI really does satisfy the definition of a tool.

This unlocks a common refrain from the booster class: "A true craftsperson uses every tool at their disposal!" Which, if you think about it for ten seconds, is ridiculous on its face. Gotta dig some holes for fence posts? Okay! Bring along every shovel on the truck, the Ditch Witch, a box of ANFO and the Bagger 293. Have the people who parrot this kind of stuff ever built _anything_ in the physical world? A true craftsperson has one _real good_ compound miter saw that they use for basically every cut on the job. They'll use it until it breaks down, then they'll replace it with a newer model of substantially the same thing. {{% margin-note %}}You know why they stick with what they know? _Because they know it._ They've invested a lot of effort learning quirks, shortcuts, and building up muscle memory on it.{{% /margin-note %}} In what world is switching tools for the sake of switching tools a remotely smart use of time?

But there's a deeper thing I wanted to touch on here. There's a random piece of advice that's been floating around my head for years: _Don't rent your livelihood._{{% margin-note side %}}I wish I knew where I picked this up from so I could properly attribute it to its source, but my research so far has turned up nothing.{{% /margin-note %}} That is to say, if there is a tool or system on which your entire professional success rests, do everything you can to ensure that it's not something you need to constantly pay other people to acquire. For example, if you own and operate a moving company, it would be wise to not need to rely on a rental company to provide a truck for you to use every day. Because if you do, you're effectively at the rental company's mercy. If they want to jack up their day rates, that hurts your bottom line. If you show up the morning before a big move and they already rented all their trucks out to other customers, tough luck.

Obviously there is nuance to it. If you're a landscaping company and you only need the Ditch Witch some days, it's less risky and more fiscally responsible to rent that. If you can't get it, it's not like the business shuts down. I'm talking about the fundamental every day stuff here: the plumber's wrenches, the musician's guitars, the photographer's camera bodies.

Paying for AI of any kind feels like something between outsourcing the work and renting a brain. Neither one is a particularly great feeling, at least to me. The outsourcing aspect is pretty clear-cut: If you are doing this as an employee, the company hired _you_ and everything you bring to the table---your judgement, your experience, your personality, etc. If you wouldn't have hired some dude off Fiverr in 2021 to do your job for you, what suddenly changed now? Even if the business paid for the license instead of you, does it really change the fact that _it ain't really you doing the work anymore?_ What do they even need you for, anyway?

The rent-a-brain aspect is more acutely alarming. And I will be blunt here: It sure does seem like the prolonged use of LLMs can reliably turn a person's mind into mush. Perhaps there's a bit of a correlation/causation aspect, but I do not like what I see out there.

Stop me if you've heard this one before: "After [however long] using AI coding assistants, there's no way I'm going back!" You know, I don't doubt that this is true. Because I'm not sure they _could_ go back. It reads like praise on the surface, but underneath it those same words betray a chilling dependence. "I gambled away my life savings, I can't stop now." "I'm now addicted to heroin, why would I give that up?" "I lost a piece of myself that I can't even remember ever having, adapt or get left behind! :rocket:" Do you actually want to be in this place you feel you can no longer escape from?

If you do knowledge work, your brain is your livelihood. Don't rent your brain, especially from companies that don't have your best interests at heart. How much do these LLM tokens actually cost, once you factor in the amortized cost of training multiple models over all the content that has ever been exposed to the internet? What does it cost once the VC money needs to be paid back, or the debts come due, or the investor class gets spooked and somebody's share price dives? How much will you need to pay each month to rent your livelihood back from these companies once your brain has completely atrophied?

We live in a _capitalist_ society. The line must go up at all costs. For a while this was easy in the technology space because computers kept getting bigger and faster. This one can play CDs! Now this one can run the hot new game! This one can (barely) stream online videos! You ever notice how that kinda petered out about a decade ago? Computers today feel pretty much like the computers did in the mid 2010s. We stopped seeing worthwhile advances in features that people were clamoring for. VR was a bit of a dud, cryptocurrency didn't meaningfully change much of anything, and the sole motivating factor for me buying my last three smartphones was "the battery in the new one works."

I doubt anybody really wants to admit it, but tech is in a terrible slump. They desperately need something, anything, to inspire that line to go up. If AI can't do it, there aren't a whole lot of other things out there to be optimistic toward.

What will you do when the frontier models start inserting "sponsored thoughts" into the work you tasked them with?

---
